{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 50.0,
  "eval_steps": 20,
  "global_step": 350,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.14285714285714285,
      "grad_norm": 0.30307790637016296,
      "learning_rate": 9.971428571428571e-05,
      "loss": 4.2812,
      "step": 1
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 0.22411523759365082,
      "learning_rate": 9.942857142857144e-05,
      "loss": 4.5469,
      "step": 2
    },
    {
      "epoch": 0.42857142857142855,
      "grad_norm": 0.44279322028160095,
      "learning_rate": 9.914285714285715e-05,
      "loss": 5.9688,
      "step": 3
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.29590025544166565,
      "learning_rate": 9.885714285714286e-05,
      "loss": 4.875,
      "step": 4
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.4120025932788849,
      "learning_rate": 9.857142857142858e-05,
      "loss": 4.4844,
      "step": 5
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 0.3014468550682068,
      "learning_rate": 9.828571428571429e-05,
      "loss": 4.3281,
      "step": 6
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.4051646590232849,
      "learning_rate": 9.8e-05,
      "loss": 5.0312,
      "step": 7
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 0.6218019723892212,
      "learning_rate": 9.771428571428572e-05,
      "loss": 5.7969,
      "step": 8
    },
    {
      "epoch": 1.2857142857142856,
      "grad_norm": 0.3433910012245178,
      "learning_rate": 9.742857142857143e-05,
      "loss": 4.0781,
      "step": 9
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.32812267541885376,
      "learning_rate": 9.714285714285715e-05,
      "loss": 4.375,
      "step": 10
    },
    {
      "epoch": 1.5714285714285714,
      "grad_norm": 0.3199671506881714,
      "learning_rate": 9.685714285714286e-05,
      "loss": 4.5156,
      "step": 11
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 0.4104658365249634,
      "learning_rate": 9.657142857142858e-05,
      "loss": 4.8125,
      "step": 12
    },
    {
      "epoch": 1.8571428571428572,
      "grad_norm": 0.46546119451522827,
      "learning_rate": 9.628571428571429e-05,
      "loss": 4.2344,
      "step": 13
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.6111242175102234,
      "learning_rate": 9.6e-05,
      "loss": 5.5156,
      "step": 14
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 0.3757239282131195,
      "learning_rate": 9.571428571428573e-05,
      "loss": 4.5625,
      "step": 15
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 0.3331593871116638,
      "learning_rate": 9.542857142857143e-05,
      "loss": 4.0469,
      "step": 16
    },
    {
      "epoch": 2.4285714285714284,
      "grad_norm": 0.4897085130214691,
      "learning_rate": 9.514285714285714e-05,
      "loss": 4.3906,
      "step": 17
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 0.37714603543281555,
      "learning_rate": 9.485714285714287e-05,
      "loss": 4.2812,
      "step": 18
    },
    {
      "epoch": 2.7142857142857144,
      "grad_norm": 0.743408739566803,
      "learning_rate": 9.457142857142858e-05,
      "loss": 6.2812,
      "step": 19
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.3795987367630005,
      "learning_rate": 9.428571428571429e-05,
      "loss": 4.1016,
      "step": 20
    },
    {
      "epoch": 2.857142857142857,
      "eval_loss": 4.359375,
      "eval_runtime": 0.921,
      "eval_samples_per_second": 2.172,
      "eval_steps_per_second": 2.172,
      "step": 20
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.5797632336616516,
      "learning_rate": 9.4e-05,
      "loss": 5.4062,
      "step": 21
    },
    {
      "epoch": 3.142857142857143,
      "grad_norm": 0.4762216806411743,
      "learning_rate": 9.371428571428572e-05,
      "loss": 4.4844,
      "step": 22
    },
    {
      "epoch": 3.2857142857142856,
      "grad_norm": 0.41083472967147827,
      "learning_rate": 9.342857142857143e-05,
      "loss": 4.125,
      "step": 23
    },
    {
      "epoch": 3.4285714285714284,
      "grad_norm": 0.40996813774108887,
      "learning_rate": 9.314285714285715e-05,
      "loss": 4.1797,
      "step": 24
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 1.031253695487976,
      "learning_rate": 9.285714285714286e-05,
      "loss": 6.8594,
      "step": 25
    },
    {
      "epoch": 3.7142857142857144,
      "grad_norm": 0.4682028293609619,
      "learning_rate": 9.257142857142858e-05,
      "loss": 3.9922,
      "step": 26
    },
    {
      "epoch": 3.857142857142857,
      "grad_norm": 0.4791443347930908,
      "learning_rate": 9.228571428571429e-05,
      "loss": 4.3906,
      "step": 27
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.5049703121185303,
      "learning_rate": 9.200000000000001e-05,
      "loss": 4.7812,
      "step": 28
    },
    {
      "epoch": 4.142857142857143,
      "grad_norm": 0.45076489448547363,
      "learning_rate": 9.171428571428572e-05,
      "loss": 4.2891,
      "step": 29
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 0.8262007832527161,
      "learning_rate": 9.142857142857143e-05,
      "loss": 6.1406,
      "step": 30
    },
    {
      "epoch": 4.428571428571429,
      "grad_norm": 0.4662427306175232,
      "learning_rate": 9.114285714285716e-05,
      "loss": 4.4844,
      "step": 31
    },
    {
      "epoch": 4.571428571428571,
      "grad_norm": 0.46207788586616516,
      "learning_rate": 9.085714285714286e-05,
      "loss": 4.125,
      "step": 32
    },
    {
      "epoch": 4.714285714285714,
      "grad_norm": 0.699458122253418,
      "learning_rate": 9.057142857142857e-05,
      "loss": 5.2969,
      "step": 33
    },
    {
      "epoch": 4.857142857142857,
      "grad_norm": 0.4642448425292969,
      "learning_rate": 9.028571428571428e-05,
      "loss": 3.9453,
      "step": 34
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.6094130277633667,
      "learning_rate": 9e-05,
      "loss": 4.2969,
      "step": 35
    },
    {
      "epoch": 5.142857142857143,
      "grad_norm": 0.5122748613357544,
      "learning_rate": 8.971428571428571e-05,
      "loss": 4.1875,
      "step": 36
    },
    {
      "epoch": 5.285714285714286,
      "grad_norm": 0.7456470131874084,
      "learning_rate": 8.942857142857142e-05,
      "loss": 5.3281,
      "step": 37
    },
    {
      "epoch": 5.428571428571429,
      "grad_norm": 0.4753117263317108,
      "learning_rate": 8.914285714285715e-05,
      "loss": 4.3672,
      "step": 38
    },
    {
      "epoch": 5.571428571428571,
      "grad_norm": 0.4859410524368286,
      "learning_rate": 8.885714285714286e-05,
      "loss": 3.875,
      "step": 39
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 0.579651415348053,
      "learning_rate": 8.857142857142857e-05,
      "loss": 4.4688,
      "step": 40
    },
    {
      "epoch": 5.714285714285714,
      "eval_loss": 4.28125,
      "eval_runtime": 0.9261,
      "eval_samples_per_second": 2.16,
      "eval_steps_per_second": 2.16,
      "step": 40
    },
    {
      "epoch": 5.857142857142857,
      "grad_norm": 0.5346992611885071,
      "learning_rate": 8.828571428571429e-05,
      "loss": 4.4219,
      "step": 41
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.7957010865211487,
      "learning_rate": 8.800000000000001e-05,
      "loss": 5.7188,
      "step": 42
    },
    {
      "epoch": 6.142857142857143,
      "grad_norm": 0.5512190461158752,
      "learning_rate": 8.771428571428572e-05,
      "loss": 4.3906,
      "step": 43
    },
    {
      "epoch": 6.285714285714286,
      "grad_norm": 0.9708210825920105,
      "learning_rate": 8.742857142857144e-05,
      "loss": 6.7031,
      "step": 44
    },
    {
      "epoch": 6.428571428571429,
      "grad_norm": 0.5783811211585999,
      "learning_rate": 8.714285714285715e-05,
      "loss": 4.5469,
      "step": 45
    },
    {
      "epoch": 6.571428571428571,
      "grad_norm": 0.5399550795555115,
      "learning_rate": 8.685714285714286e-05,
      "loss": 4.0625,
      "step": 46
    },
    {
      "epoch": 6.714285714285714,
      "grad_norm": 0.47415024042129517,
      "learning_rate": 8.657142857142858e-05,
      "loss": 4.1406,
      "step": 47
    },
    {
      "epoch": 6.857142857142857,
      "grad_norm": 0.5028749704360962,
      "learning_rate": 8.62857142857143e-05,
      "loss": 4.1797,
      "step": 48
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.4392474293708801,
      "learning_rate": 8.6e-05,
      "loss": 3.875,
      "step": 49
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.4643971621990204,
      "learning_rate": 8.571428571428571e-05,
      "loss": 3.8672,
      "step": 50
    },
    {
      "epoch": 7.285714285714286,
      "grad_norm": 2.0206620693206787,
      "learning_rate": 8.542857142857144e-05,
      "loss": 5.8281,
      "step": 51
    },
    {
      "epoch": 7.428571428571429,
      "grad_norm": 0.6301982402801514,
      "learning_rate": 8.514285714285714e-05,
      "loss": 4.2656,
      "step": 52
    },
    {
      "epoch": 7.571428571428571,
      "grad_norm": 0.5358434319496155,
      "learning_rate": 8.485714285714285e-05,
      "loss": 4.0391,
      "step": 53
    },
    {
      "epoch": 7.714285714285714,
      "grad_norm": 0.8479806184768677,
      "learning_rate": 8.457142857142858e-05,
      "loss": 4.9375,
      "step": 54
    },
    {
      "epoch": 7.857142857142857,
      "grad_norm": 0.5832212567329407,
      "learning_rate": 8.428571428571429e-05,
      "loss": 4.2969,
      "step": 55
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.5310774445533752,
      "learning_rate": 8.4e-05,
      "loss": 4.4375,
      "step": 56
    },
    {
      "epoch": 8.142857142857142,
      "grad_norm": 0.5172730684280396,
      "learning_rate": 8.371428571428572e-05,
      "loss": 4.2188,
      "step": 57
    },
    {
      "epoch": 8.285714285714286,
      "grad_norm": 0.6410463452339172,
      "learning_rate": 8.342857142857143e-05,
      "loss": 5.0625,
      "step": 58
    },
    {
      "epoch": 8.428571428571429,
      "grad_norm": 0.5357874035835266,
      "learning_rate": 8.314285714285715e-05,
      "loss": 3.9531,
      "step": 59
    },
    {
      "epoch": 8.571428571428571,
      "grad_norm": 1.1648179292678833,
      "learning_rate": 8.285714285714287e-05,
      "loss": 5.6406,
      "step": 60
    },
    {
      "epoch": 8.571428571428571,
      "eval_loss": 4.1875,
      "eval_runtime": 0.9218,
      "eval_samples_per_second": 2.17,
      "eval_steps_per_second": 2.17,
      "step": 60
    },
    {
      "epoch": 8.714285714285714,
      "grad_norm": 0.5627377033233643,
      "learning_rate": 8.257142857142858e-05,
      "loss": 4.4375,
      "step": 61
    },
    {
      "epoch": 8.857142857142858,
      "grad_norm": 0.4877268970012665,
      "learning_rate": 8.228571428571429e-05,
      "loss": 3.9688,
      "step": 62
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.6127955913543701,
      "learning_rate": 8.2e-05,
      "loss": 4.25,
      "step": 63
    },
    {
      "epoch": 9.142857142857142,
      "grad_norm": 0.5432344675064087,
      "learning_rate": 8.171428571428572e-05,
      "loss": 4.1484,
      "step": 64
    },
    {
      "epoch": 9.285714285714286,
      "grad_norm": 0.5115408897399902,
      "learning_rate": 8.142857142857143e-05,
      "loss": 4.0469,
      "step": 65
    },
    {
      "epoch": 9.428571428571429,
      "grad_norm": 0.7633219361305237,
      "learning_rate": 8.114285714285714e-05,
      "loss": 5.3125,
      "step": 66
    },
    {
      "epoch": 9.571428571428571,
      "grad_norm": 0.5940119624137878,
      "learning_rate": 8.085714285714287e-05,
      "loss": 4.1562,
      "step": 67
    },
    {
      "epoch": 9.714285714285714,
      "grad_norm": 0.5536668300628662,
      "learning_rate": 8.057142857142857e-05,
      "loss": 3.9375,
      "step": 68
    },
    {
      "epoch": 9.857142857142858,
      "grad_norm": 0.5319676399230957,
      "learning_rate": 8.028571428571428e-05,
      "loss": 4.4062,
      "step": 69
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.8304377198219299,
      "learning_rate": 8e-05,
      "loss": 5.1719,
      "step": 70
    },
    {
      "epoch": 10.142857142857142,
      "grad_norm": 0.5255534648895264,
      "learning_rate": 7.971428571428572e-05,
      "loss": 4.3438,
      "step": 71
    },
    {
      "epoch": 10.285714285714286,
      "grad_norm": 0.6362151503562927,
      "learning_rate": 7.942857142857143e-05,
      "loss": 4.1562,
      "step": 72
    },
    {
      "epoch": 10.428571428571429,
      "grad_norm": 0.5423740148544312,
      "learning_rate": 7.914285714285715e-05,
      "loss": 4.0391,
      "step": 73
    },
    {
      "epoch": 10.571428571428571,
      "grad_norm": 1.03627347946167,
      "learning_rate": 7.885714285714286e-05,
      "loss": 5.6719,
      "step": 74
    },
    {
      "epoch": 10.714285714285714,
      "grad_norm": 0.5526016354560852,
      "learning_rate": 7.857142857142858e-05,
      "loss": 4.1875,
      "step": 75
    },
    {
      "epoch": 10.857142857142858,
      "grad_norm": 0.4836186468601227,
      "learning_rate": 7.828571428571429e-05,
      "loss": 3.5,
      "step": 76
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.7834739089012146,
      "learning_rate": 7.800000000000001e-05,
      "loss": 4.9609,
      "step": 77
    },
    {
      "epoch": 11.142857142857142,
      "grad_norm": 0.7011104226112366,
      "learning_rate": 7.771428571428572e-05,
      "loss": 5.0156,
      "step": 78
    },
    {
      "epoch": 11.285714285714286,
      "grad_norm": 0.44562652707099915,
      "learning_rate": 7.742857142857143e-05,
      "loss": 4.0234,
      "step": 79
    },
    {
      "epoch": 11.428571428571429,
      "grad_norm": 0.48953717947006226,
      "learning_rate": 7.714285714285715e-05,
      "loss": 3.4609,
      "step": 80
    },
    {
      "epoch": 11.428571428571429,
      "eval_loss": 4.125,
      "eval_runtime": 0.9221,
      "eval_samples_per_second": 2.169,
      "eval_steps_per_second": 2.169,
      "step": 80
    },
    {
      "epoch": 11.571428571428571,
      "grad_norm": 0.5835520029067993,
      "learning_rate": 7.685714285714286e-05,
      "loss": 4.2031,
      "step": 81
    },
    {
      "epoch": 11.714285714285714,
      "grad_norm": 0.5183902382850647,
      "learning_rate": 7.657142857142857e-05,
      "loss": 4.4844,
      "step": 82
    },
    {
      "epoch": 11.857142857142858,
      "grad_norm": 1.0487186908721924,
      "learning_rate": 7.62857142857143e-05,
      "loss": 5.4531,
      "step": 83
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.4396060109138489,
      "learning_rate": 7.6e-05,
      "loss": 3.9531,
      "step": 84
    },
    {
      "epoch": 12.142857142857142,
      "grad_norm": 0.7461350560188293,
      "learning_rate": 7.571428571428571e-05,
      "loss": 5.1094,
      "step": 85
    },
    {
      "epoch": 12.285714285714286,
      "grad_norm": 0.4630442261695862,
      "learning_rate": 7.542857142857144e-05,
      "loss": 4.3906,
      "step": 86
    },
    {
      "epoch": 12.428571428571429,
      "grad_norm": 0.4771275520324707,
      "learning_rate": 7.514285714285715e-05,
      "loss": 3.7031,
      "step": 87
    },
    {
      "epoch": 12.571428571428571,
      "grad_norm": 0.7445326447486877,
      "learning_rate": 7.485714285714285e-05,
      "loss": 3.9609,
      "step": 88
    },
    {
      "epoch": 12.714285714285714,
      "grad_norm": 0.4623836278915405,
      "learning_rate": 7.457142857142856e-05,
      "loss": 4.0625,
      "step": 89
    },
    {
      "epoch": 12.857142857142858,
      "grad_norm": 0.4595640003681183,
      "learning_rate": 7.428571428571429e-05,
      "loss": 3.7812,
      "step": 90
    },
    {
      "epoch": 13.0,
      "grad_norm": 0.8118723034858704,
      "learning_rate": 7.4e-05,
      "loss": 5.4062,
      "step": 91
    },
    {
      "epoch": 13.142857142857142,
      "grad_norm": 0.6984740495681763,
      "learning_rate": 7.371428571428572e-05,
      "loss": 3.8125,
      "step": 92
    },
    {
      "epoch": 13.285714285714286,
      "grad_norm": 0.9924649000167847,
      "learning_rate": 7.342857142857144e-05,
      "loss": 4.5938,
      "step": 93
    },
    {
      "epoch": 13.428571428571429,
      "grad_norm": 0.4912264049053192,
      "learning_rate": 7.314285714285715e-05,
      "loss": 3.9531,
      "step": 94
    },
    {
      "epoch": 13.571428571428571,
      "grad_norm": 0.6500368714332581,
      "learning_rate": 7.285714285714286e-05,
      "loss": 5.6719,
      "step": 95
    },
    {
      "epoch": 13.714285714285714,
      "grad_norm": 0.5291724801063538,
      "learning_rate": 7.257142857142858e-05,
      "loss": 3.8672,
      "step": 96
    },
    {
      "epoch": 13.857142857142858,
      "grad_norm": 0.503835141658783,
      "learning_rate": 7.228571428571429e-05,
      "loss": 4.3125,
      "step": 97
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.5228161811828613,
      "learning_rate": 7.2e-05,
      "loss": 4.1719,
      "step": 98
    },
    {
      "epoch": 14.142857142857142,
      "grad_norm": 0.5973784923553467,
      "learning_rate": 7.171428571428572e-05,
      "loss": 4.1016,
      "step": 99
    },
    {
      "epoch": 14.285714285714286,
      "grad_norm": 0.664068341255188,
      "learning_rate": 7.142857142857143e-05,
      "loss": 4.0,
      "step": 100
    },
    {
      "epoch": 14.285714285714286,
      "eval_loss": 4.1015625,
      "eval_runtime": 0.9227,
      "eval_samples_per_second": 2.168,
      "eval_steps_per_second": 2.168,
      "step": 100
    },
    {
      "epoch": 14.428571428571429,
      "grad_norm": 0.47168219089508057,
      "learning_rate": 7.114285714285714e-05,
      "loss": 3.5234,
      "step": 101
    },
    {
      "epoch": 14.571428571428571,
      "grad_norm": 0.4690355360507965,
      "learning_rate": 7.085714285714285e-05,
      "loss": 4.1016,
      "step": 102
    },
    {
      "epoch": 14.714285714285714,
      "grad_norm": 0.510428786277771,
      "learning_rate": 7.057142857142858e-05,
      "loss": 4.1094,
      "step": 103
    },
    {
      "epoch": 14.857142857142858,
      "grad_norm": 0.7893761396408081,
      "learning_rate": 7.028571428571428e-05,
      "loss": 4.8906,
      "step": 104
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.7216686010360718,
      "learning_rate": 7e-05,
      "loss": 5.2578,
      "step": 105
    },
    {
      "epoch": 15.142857142857142,
      "grad_norm": 0.4565909206867218,
      "learning_rate": 6.971428571428572e-05,
      "loss": 4.2031,
      "step": 106
    },
    {
      "epoch": 15.285714285714286,
      "grad_norm": 0.8038133978843689,
      "learning_rate": 6.942857142857143e-05,
      "loss": 4.8516,
      "step": 107
    },
    {
      "epoch": 15.428571428571429,
      "grad_norm": 0.46576929092407227,
      "learning_rate": 6.914285714285715e-05,
      "loss": 3.7188,
      "step": 108
    },
    {
      "epoch": 15.571428571428571,
      "grad_norm": 0.46775779128074646,
      "learning_rate": 6.885714285714286e-05,
      "loss": 3.6562,
      "step": 109
    },
    {
      "epoch": 15.714285714285714,
      "grad_norm": 0.5892505049705505,
      "learning_rate": 6.857142857142858e-05,
      "loss": 3.9531,
      "step": 110
    },
    {
      "epoch": 15.857142857142858,
      "grad_norm": 0.9103662371635437,
      "learning_rate": 6.828571428571429e-05,
      "loss": 5.6562,
      "step": 111
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.5159646272659302,
      "learning_rate": 6.800000000000001e-05,
      "loss": 3.9688,
      "step": 112
    },
    {
      "epoch": 16.142857142857142,
      "grad_norm": 0.7345803380012512,
      "learning_rate": 6.771428571428572e-05,
      "loss": 4.0547,
      "step": 113
    },
    {
      "epoch": 16.285714285714285,
      "grad_norm": 0.5981246829032898,
      "learning_rate": 6.742857142857143e-05,
      "loss": 3.9375,
      "step": 114
    },
    {
      "epoch": 16.428571428571427,
      "grad_norm": 0.54677414894104,
      "learning_rate": 6.714285714285714e-05,
      "loss": 4.0391,
      "step": 115
    },
    {
      "epoch": 16.571428571428573,
      "grad_norm": 0.518820583820343,
      "learning_rate": 6.685714285714286e-05,
      "loss": 3.9531,
      "step": 116
    },
    {
      "epoch": 16.714285714285715,
      "grad_norm": 1.0854839086532593,
      "learning_rate": 6.657142857142857e-05,
      "loss": 4.0234,
      "step": 117
    },
    {
      "epoch": 16.857142857142858,
      "grad_norm": 0.4324638247489929,
      "learning_rate": 6.628571428571428e-05,
      "loss": 3.6016,
      "step": 118
    },
    {
      "epoch": 17.0,
      "grad_norm": 1.2176140546798706,
      "learning_rate": 6.6e-05,
      "loss": 6.2031,
      "step": 119
    },
    {
      "epoch": 17.142857142857142,
      "grad_norm": 1.4146673679351807,
      "learning_rate": 6.571428571428571e-05,
      "loss": 4.8438,
      "step": 120
    },
    {
      "epoch": 17.142857142857142,
      "eval_loss": 4.0859375,
      "eval_runtime": 0.927,
      "eval_samples_per_second": 2.158,
      "eval_steps_per_second": 2.158,
      "step": 120
    },
    {
      "epoch": 17.285714285714285,
      "grad_norm": 0.4481125771999359,
      "learning_rate": 6.542857142857142e-05,
      "loss": 4.1328,
      "step": 121
    },
    {
      "epoch": 17.428571428571427,
      "grad_norm": 0.4702650010585785,
      "learning_rate": 6.514285714285715e-05,
      "loss": 3.9219,
      "step": 122
    },
    {
      "epoch": 17.571428571428573,
      "grad_norm": 0.5083480477333069,
      "learning_rate": 6.485714285714286e-05,
      "loss": 4.3438,
      "step": 123
    },
    {
      "epoch": 17.714285714285715,
      "grad_norm": 0.5278275609016418,
      "learning_rate": 6.457142857142856e-05,
      "loss": 3.7656,
      "step": 124
    },
    {
      "epoch": 17.857142857142858,
      "grad_norm": 0.5086402297019958,
      "learning_rate": 6.428571428571429e-05,
      "loss": 3.7031,
      "step": 125
    },
    {
      "epoch": 18.0,
      "grad_norm": 0.7211263179779053,
      "learning_rate": 6.400000000000001e-05,
      "loss": 5.0469,
      "step": 126
    },
    {
      "epoch": 18.142857142857142,
      "grad_norm": 0.8666334748268127,
      "learning_rate": 6.371428571428572e-05,
      "loss": 4.8359,
      "step": 127
    },
    {
      "epoch": 18.285714285714285,
      "grad_norm": 0.4650743305683136,
      "learning_rate": 6.342857142857143e-05,
      "loss": 3.875,
      "step": 128
    },
    {
      "epoch": 18.428571428571427,
      "grad_norm": 0.6743879914283752,
      "learning_rate": 6.314285714285715e-05,
      "loss": 3.8906,
      "step": 129
    },
    {
      "epoch": 18.571428571428573,
      "grad_norm": 0.44042783975601196,
      "learning_rate": 6.285714285714286e-05,
      "loss": 4.0234,
      "step": 130
    },
    {
      "epoch": 18.714285714285715,
      "grad_norm": 0.5066589117050171,
      "learning_rate": 6.257142857142857e-05,
      "loss": 3.5625,
      "step": 131
    },
    {
      "epoch": 18.857142857142858,
      "grad_norm": 0.4675266444683075,
      "learning_rate": 6.22857142857143e-05,
      "loss": 4.1016,
      "step": 132
    },
    {
      "epoch": 19.0,
      "grad_norm": 1.0811771154403687,
      "learning_rate": 6.2e-05,
      "loss": 5.3906,
      "step": 133
    },
    {
      "epoch": 19.142857142857142,
      "grad_norm": 0.793323814868927,
      "learning_rate": 6.171428571428571e-05,
      "loss": 3.8906,
      "step": 134
    },
    {
      "epoch": 19.285714285714285,
      "grad_norm": 0.47139057517051697,
      "learning_rate": 6.142857142857143e-05,
      "loss": 3.7891,
      "step": 135
    },
    {
      "epoch": 19.428571428571427,
      "grad_norm": 1.8437491655349731,
      "learning_rate": 6.114285714285714e-05,
      "loss": 5.4688,
      "step": 136
    },
    {
      "epoch": 19.571428571428573,
      "grad_norm": 0.5206932425498962,
      "learning_rate": 6.085714285714286e-05,
      "loss": 3.9844,
      "step": 137
    },
    {
      "epoch": 19.714285714285715,
      "grad_norm": 0.5104583501815796,
      "learning_rate": 6.0571428571428576e-05,
      "loss": 4.0312,
      "step": 138
    },
    {
      "epoch": 19.857142857142858,
      "grad_norm": 0.8778303265571594,
      "learning_rate": 6.028571428571429e-05,
      "loss": 4.4766,
      "step": 139
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.5315064787864685,
      "learning_rate": 6e-05,
      "loss": 4.0078,
      "step": 140
    },
    {
      "epoch": 20.0,
      "eval_loss": 4.0625,
      "eval_runtime": 0.9223,
      "eval_samples_per_second": 2.168,
      "eval_steps_per_second": 2.168,
      "step": 140
    },
    {
      "epoch": 20.142857142857142,
      "grad_norm": 0.4261026084423065,
      "learning_rate": 5.9714285714285724e-05,
      "loss": 3.5859,
      "step": 141
    },
    {
      "epoch": 20.285714285714285,
      "grad_norm": 1.7201058864593506,
      "learning_rate": 5.9428571428571434e-05,
      "loss": 5.0312,
      "step": 142
    },
    {
      "epoch": 20.428571428571427,
      "grad_norm": 0.5551583766937256,
      "learning_rate": 5.914285714285714e-05,
      "loss": 4.2812,
      "step": 143
    },
    {
      "epoch": 20.571428571428573,
      "grad_norm": 0.518366813659668,
      "learning_rate": 5.885714285714285e-05,
      "loss": 3.7891,
      "step": 144
    },
    {
      "epoch": 20.714285714285715,
      "grad_norm": 0.9132083654403687,
      "learning_rate": 5.8571428571428575e-05,
      "loss": 5.2109,
      "step": 145
    },
    {
      "epoch": 20.857142857142858,
      "grad_norm": 0.7203488349914551,
      "learning_rate": 5.828571428571429e-05,
      "loss": 3.9766,
      "step": 146
    },
    {
      "epoch": 21.0,
      "grad_norm": 0.45919933915138245,
      "learning_rate": 5.8e-05,
      "loss": 3.7188,
      "step": 147
    },
    {
      "epoch": 21.142857142857142,
      "grad_norm": 0.6196919679641724,
      "learning_rate": 5.771428571428572e-05,
      "loss": 4.0781,
      "step": 148
    },
    {
      "epoch": 21.285714285714285,
      "grad_norm": 0.6703405380249023,
      "learning_rate": 5.742857142857143e-05,
      "loss": 3.8828,
      "step": 149
    },
    {
      "epoch": 21.428571428571427,
      "grad_norm": 0.6460959315299988,
      "learning_rate": 5.714285714285714e-05,
      "loss": 4.4219,
      "step": 150
    },
    {
      "epoch": 21.571428571428573,
      "grad_norm": 0.5817353129386902,
      "learning_rate": 5.6857142857142865e-05,
      "loss": 3.7266,
      "step": 151
    },
    {
      "epoch": 21.714285714285715,
      "grad_norm": 0.9347333908081055,
      "learning_rate": 5.6571428571428574e-05,
      "loss": 5.2266,
      "step": 152
    },
    {
      "epoch": 21.857142857142858,
      "grad_norm": 0.48231589794158936,
      "learning_rate": 5.628571428571428e-05,
      "loss": 3.7812,
      "step": 153
    },
    {
      "epoch": 22.0,
      "grad_norm": 0.7483488321304321,
      "learning_rate": 5.6000000000000006e-05,
      "loss": 4.4609,
      "step": 154
    },
    {
      "epoch": 22.142857142857142,
      "grad_norm": 0.6131139397621155,
      "learning_rate": 5.571428571428572e-05,
      "loss": 3.9531,
      "step": 155
    },
    {
      "epoch": 22.285714285714285,
      "grad_norm": 0.8671228885650635,
      "learning_rate": 5.542857142857143e-05,
      "loss": 3.6875,
      "step": 156
    },
    {
      "epoch": 22.428571428571427,
      "grad_norm": 0.5993916988372803,
      "learning_rate": 5.514285714285714e-05,
      "loss": 3.9688,
      "step": 157
    },
    {
      "epoch": 22.571428571428573,
      "grad_norm": 0.7809825539588928,
      "learning_rate": 5.485714285714286e-05,
      "loss": 5.4844,
      "step": 158
    },
    {
      "epoch": 22.714285714285715,
      "grad_norm": 0.4932187795639038,
      "learning_rate": 5.457142857142857e-05,
      "loss": 3.9062,
      "step": 159
    },
    {
      "epoch": 22.857142857142858,
      "grad_norm": 0.69333416223526,
      "learning_rate": 5.428571428571428e-05,
      "loss": 4.3828,
      "step": 160
    },
    {
      "epoch": 22.857142857142858,
      "eval_loss": 4.0625,
      "eval_runtime": 0.9218,
      "eval_samples_per_second": 2.17,
      "eval_steps_per_second": 2.17,
      "step": 160
    },
    {
      "epoch": 23.0,
      "grad_norm": 0.4979698359966278,
      "learning_rate": 5.4000000000000005e-05,
      "loss": 3.9141,
      "step": 161
    },
    {
      "epoch": 23.142857142857142,
      "grad_norm": 0.5156306028366089,
      "learning_rate": 5.3714285714285714e-05,
      "loss": 4.1953,
      "step": 162
    },
    {
      "epoch": 23.285714285714285,
      "grad_norm": 0.5459060072898865,
      "learning_rate": 5.342857142857143e-05,
      "loss": 3.3594,
      "step": 163
    },
    {
      "epoch": 23.428571428571427,
      "grad_norm": 0.6595309972763062,
      "learning_rate": 5.314285714285715e-05,
      "loss": 4.7188,
      "step": 164
    },
    {
      "epoch": 23.571428571428573,
      "grad_norm": 0.8508357405662537,
      "learning_rate": 5.285714285714286e-05,
      "loss": 5.2891,
      "step": 165
    },
    {
      "epoch": 23.714285714285715,
      "grad_norm": 0.5285882949829102,
      "learning_rate": 5.257142857142857e-05,
      "loss": 3.9609,
      "step": 166
    },
    {
      "epoch": 23.857142857142858,
      "grad_norm": 0.7417558431625366,
      "learning_rate": 5.2285714285714294e-05,
      "loss": 3.9609,
      "step": 167
    },
    {
      "epoch": 24.0,
      "grad_norm": 0.5651102662086487,
      "learning_rate": 5.2000000000000004e-05,
      "loss": 3.9219,
      "step": 168
    },
    {
      "epoch": 24.142857142857142,
      "grad_norm": 0.7979351282119751,
      "learning_rate": 5.171428571428571e-05,
      "loss": 4.8047,
      "step": 169
    },
    {
      "epoch": 24.285714285714285,
      "grad_norm": 0.7277452945709229,
      "learning_rate": 5.142857142857143e-05,
      "loss": 3.5078,
      "step": 170
    },
    {
      "epoch": 24.428571428571427,
      "grad_norm": 0.5512468218803406,
      "learning_rate": 5.1142857142857145e-05,
      "loss": 4.0391,
      "step": 171
    },
    {
      "epoch": 24.571428571428573,
      "grad_norm": 0.8015908002853394,
      "learning_rate": 5.085714285714286e-05,
      "loss": 5.3047,
      "step": 172
    },
    {
      "epoch": 24.714285714285715,
      "grad_norm": 0.7966621518135071,
      "learning_rate": 5.057142857142857e-05,
      "loss": 3.7031,
      "step": 173
    },
    {
      "epoch": 24.857142857142858,
      "grad_norm": 0.5316379070281982,
      "learning_rate": 5.028571428571429e-05,
      "loss": 3.9453,
      "step": 174
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.581738293170929,
      "learning_rate": 5e-05,
      "loss": 4.1562,
      "step": 175
    },
    {
      "epoch": 25.142857142857142,
      "grad_norm": 1.3133972883224487,
      "learning_rate": 4.971428571428572e-05,
      "loss": 4.9844,
      "step": 176
    },
    {
      "epoch": 25.285714285714285,
      "grad_norm": 0.5330259203910828,
      "learning_rate": 4.942857142857143e-05,
      "loss": 3.9219,
      "step": 177
    },
    {
      "epoch": 25.428571428571427,
      "grad_norm": 0.5477870106697083,
      "learning_rate": 4.9142857142857144e-05,
      "loss": 3.8672,
      "step": 178
    },
    {
      "epoch": 25.571428571428573,
      "grad_norm": 0.8076517581939697,
      "learning_rate": 4.885714285714286e-05,
      "loss": 3.9453,
      "step": 179
    },
    {
      "epoch": 25.714285714285715,
      "grad_norm": 0.5747343301773071,
      "learning_rate": 4.8571428571428576e-05,
      "loss": 3.9688,
      "step": 180
    },
    {
      "epoch": 25.714285714285715,
      "eval_loss": 4.0390625,
      "eval_runtime": 0.9244,
      "eval_samples_per_second": 2.164,
      "eval_steps_per_second": 2.164,
      "step": 180
    },
    {
      "epoch": 25.857142857142858,
      "grad_norm": 0.48316213488578796,
      "learning_rate": 4.828571428571429e-05,
      "loss": 3.75,
      "step": 181
    },
    {
      "epoch": 26.0,
      "grad_norm": 0.8394613862037659,
      "learning_rate": 4.8e-05,
      "loss": 4.8203,
      "step": 182
    },
    {
      "epoch": 26.142857142857142,
      "grad_norm": 0.5619187355041504,
      "learning_rate": 4.771428571428572e-05,
      "loss": 3.3516,
      "step": 183
    },
    {
      "epoch": 26.285714285714285,
      "grad_norm": 0.8321506381034851,
      "learning_rate": 4.742857142857143e-05,
      "loss": 4.7344,
      "step": 184
    },
    {
      "epoch": 26.428571428571427,
      "grad_norm": 0.5585916042327881,
      "learning_rate": 4.714285714285714e-05,
      "loss": 4.2344,
      "step": 185
    },
    {
      "epoch": 26.571428571428573,
      "grad_norm": 0.5236915946006775,
      "learning_rate": 4.685714285714286e-05,
      "loss": 3.7188,
      "step": 186
    },
    {
      "epoch": 26.714285714285715,
      "grad_norm": 0.5475133061408997,
      "learning_rate": 4.6571428571428575e-05,
      "loss": 4.125,
      "step": 187
    },
    {
      "epoch": 26.857142857142858,
      "grad_norm": 0.7348372340202332,
      "learning_rate": 4.628571428571429e-05,
      "loss": 5.2891,
      "step": 188
    },
    {
      "epoch": 27.0,
      "grad_norm": 0.5446102619171143,
      "learning_rate": 4.600000000000001e-05,
      "loss": 3.8359,
      "step": 189
    },
    {
      "epoch": 27.142857142857142,
      "grad_norm": 0.5413941740989685,
      "learning_rate": 4.5714285714285716e-05,
      "loss": 4.1719,
      "step": 190
    },
    {
      "epoch": 27.285714285714285,
      "grad_norm": 0.5801330804824829,
      "learning_rate": 4.542857142857143e-05,
      "loss": 4.0781,
      "step": 191
    },
    {
      "epoch": 27.428571428571427,
      "grad_norm": 0.5838046669960022,
      "learning_rate": 4.514285714285714e-05,
      "loss": 3.5625,
      "step": 192
    },
    {
      "epoch": 27.571428571428573,
      "grad_norm": 1.1868032217025757,
      "learning_rate": 4.485714285714286e-05,
      "loss": 5.1016,
      "step": 193
    },
    {
      "epoch": 27.714285714285715,
      "grad_norm": 0.5900533199310303,
      "learning_rate": 4.4571428571428574e-05,
      "loss": 3.8984,
      "step": 194
    },
    {
      "epoch": 27.857142857142858,
      "grad_norm": 0.6136186718940735,
      "learning_rate": 4.428571428571428e-05,
      "loss": 4.6719,
      "step": 195
    },
    {
      "epoch": 28.0,
      "grad_norm": 0.7284982204437256,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 3.7188,
      "step": 196
    },
    {
      "epoch": 28.142857142857142,
      "grad_norm": 0.5614672899246216,
      "learning_rate": 4.371428571428572e-05,
      "loss": 3.7109,
      "step": 197
    },
    {
      "epoch": 28.285714285714285,
      "grad_norm": 0.6096632480621338,
      "learning_rate": 4.342857142857143e-05,
      "loss": 3.9766,
      "step": 198
    },
    {
      "epoch": 28.428571428571427,
      "grad_norm": 0.6867864727973938,
      "learning_rate": 4.314285714285715e-05,
      "loss": 3.8047,
      "step": 199
    },
    {
      "epoch": 28.571428571428573,
      "grad_norm": 1.0786939859390259,
      "learning_rate": 4.2857142857142856e-05,
      "loss": 4.9375,
      "step": 200
    },
    {
      "epoch": 28.571428571428573,
      "eval_loss": 4.0390625,
      "eval_runtime": 0.9228,
      "eval_samples_per_second": 2.167,
      "eval_steps_per_second": 2.167,
      "step": 200
    },
    {
      "epoch": 28.714285714285715,
      "grad_norm": 0.5952097177505493,
      "learning_rate": 4.257142857142857e-05,
      "loss": 3.875,
      "step": 201
    },
    {
      "epoch": 28.857142857142858,
      "grad_norm": 0.8702692985534668,
      "learning_rate": 4.228571428571429e-05,
      "loss": 5.0938,
      "step": 202
    },
    {
      "epoch": 29.0,
      "grad_norm": 0.8719177842140198,
      "learning_rate": 4.2e-05,
      "loss": 3.6406,
      "step": 203
    },
    {
      "epoch": 29.142857142857142,
      "grad_norm": 0.7056592702865601,
      "learning_rate": 4.1714285714285714e-05,
      "loss": 4.5312,
      "step": 204
    },
    {
      "epoch": 29.285714285714285,
      "grad_norm": 0.7536442875862122,
      "learning_rate": 4.1428571428571437e-05,
      "loss": 3.4844,
      "step": 205
    },
    {
      "epoch": 29.428571428571427,
      "grad_norm": 0.8886164426803589,
      "learning_rate": 4.1142857142857146e-05,
      "loss": 5.1641,
      "step": 206
    },
    {
      "epoch": 29.571428571428573,
      "grad_norm": 0.6396700739860535,
      "learning_rate": 4.085714285714286e-05,
      "loss": 3.9141,
      "step": 207
    },
    {
      "epoch": 29.714285714285715,
      "grad_norm": 0.5852378010749817,
      "learning_rate": 4.057142857142857e-05,
      "loss": 3.875,
      "step": 208
    },
    {
      "epoch": 29.857142857142858,
      "grad_norm": 0.5544146299362183,
      "learning_rate": 4.028571428571429e-05,
      "loss": 4.1484,
      "step": 209
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.6421915888786316,
      "learning_rate": 4e-05,
      "loss": 3.8906,
      "step": 210
    },
    {
      "epoch": 30.142857142857142,
      "grad_norm": 0.9427368640899658,
      "learning_rate": 3.971428571428571e-05,
      "loss": 5.1797,
      "step": 211
    },
    {
      "epoch": 30.285714285714285,
      "grad_norm": 0.954902708530426,
      "learning_rate": 3.942857142857143e-05,
      "loss": 5.0156,
      "step": 212
    },
    {
      "epoch": 30.428571428571427,
      "grad_norm": 0.5956821441650391,
      "learning_rate": 3.9142857142857145e-05,
      "loss": 3.4609,
      "step": 213
    },
    {
      "epoch": 30.571428571428573,
      "grad_norm": 0.6082329154014587,
      "learning_rate": 3.885714285714286e-05,
      "loss": 4.125,
      "step": 214
    },
    {
      "epoch": 30.714285714285715,
      "grad_norm": 0.6007121205329895,
      "learning_rate": 3.857142857142858e-05,
      "loss": 3.5625,
      "step": 215
    },
    {
      "epoch": 30.857142857142858,
      "grad_norm": 0.582324206829071,
      "learning_rate": 3.8285714285714286e-05,
      "loss": 3.9766,
      "step": 216
    },
    {
      "epoch": 31.0,
      "grad_norm": 0.5013375282287598,
      "learning_rate": 3.8e-05,
      "loss": 3.7891,
      "step": 217
    },
    {
      "epoch": 31.142857142857142,
      "grad_norm": 0.5604518055915833,
      "learning_rate": 3.771428571428572e-05,
      "loss": 4.0469,
      "step": 218
    },
    {
      "epoch": 31.285714285714285,
      "grad_norm": 0.6528628468513489,
      "learning_rate": 3.742857142857143e-05,
      "loss": 4.1562,
      "step": 219
    },
    {
      "epoch": 31.428571428571427,
      "grad_norm": 0.6281904578208923,
      "learning_rate": 3.7142857142857143e-05,
      "loss": 4.5859,
      "step": 220
    },
    {
      "epoch": 31.428571428571427,
      "eval_loss": 4.0390625,
      "eval_runtime": 0.9204,
      "eval_samples_per_second": 2.173,
      "eval_steps_per_second": 2.173,
      "step": 220
    },
    {
      "epoch": 31.571428571428573,
      "grad_norm": 0.581699788570404,
      "learning_rate": 3.685714285714286e-05,
      "loss": 3.8516,
      "step": 221
    },
    {
      "epoch": 31.714285714285715,
      "grad_norm": 0.8420164585113525,
      "learning_rate": 3.6571428571428576e-05,
      "loss": 5.2266,
      "step": 222
    },
    {
      "epoch": 31.857142857142858,
      "grad_norm": 0.7766823768615723,
      "learning_rate": 3.628571428571429e-05,
      "loss": 3.4609,
      "step": 223
    },
    {
      "epoch": 32.0,
      "grad_norm": 0.5344550609588623,
      "learning_rate": 3.6e-05,
      "loss": 3.6641,
      "step": 224
    },
    {
      "epoch": 32.142857142857146,
      "grad_norm": 0.6718422174453735,
      "learning_rate": 3.571428571428572e-05,
      "loss": 4.2188,
      "step": 225
    },
    {
      "epoch": 32.285714285714285,
      "grad_norm": 0.48935720324516296,
      "learning_rate": 3.5428571428571426e-05,
      "loss": 3.7812,
      "step": 226
    },
    {
      "epoch": 32.42857142857143,
      "grad_norm": 37.107791900634766,
      "learning_rate": 3.514285714285714e-05,
      "loss": 5.1484,
      "step": 227
    },
    {
      "epoch": 32.57142857142857,
      "grad_norm": 0.7651510238647461,
      "learning_rate": 3.485714285714286e-05,
      "loss": 4.75,
      "step": 228
    },
    {
      "epoch": 32.714285714285715,
      "grad_norm": 1.0179805755615234,
      "learning_rate": 3.4571428571428574e-05,
      "loss": 4.0859,
      "step": 229
    },
    {
      "epoch": 32.857142857142854,
      "grad_norm": 0.7018862962722778,
      "learning_rate": 3.428571428571429e-05,
      "loss": 3.4766,
      "step": 230
    },
    {
      "epoch": 33.0,
      "grad_norm": 0.5433589816093445,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 3.5859,
      "step": 231
    },
    {
      "epoch": 33.142857142857146,
      "grad_norm": 0.5954104065895081,
      "learning_rate": 3.3714285714285716e-05,
      "loss": 4.125,
      "step": 232
    },
    {
      "epoch": 33.285714285714285,
      "grad_norm": 0.9015368223190308,
      "learning_rate": 3.342857142857143e-05,
      "loss": 4.1016,
      "step": 233
    },
    {
      "epoch": 33.42857142857143,
      "grad_norm": 0.5896873474121094,
      "learning_rate": 3.314285714285714e-05,
      "loss": 3.6875,
      "step": 234
    },
    {
      "epoch": 33.57142857142857,
      "grad_norm": 0.5091751217842102,
      "learning_rate": 3.285714285714286e-05,
      "loss": 3.3672,
      "step": 235
    },
    {
      "epoch": 33.714285714285715,
      "grad_norm": 0.9962267875671387,
      "learning_rate": 3.257142857142857e-05,
      "loss": 5.0781,
      "step": 236
    },
    {
      "epoch": 33.857142857142854,
      "grad_norm": 0.7012827396392822,
      "learning_rate": 3.228571428571428e-05,
      "loss": 3.9609,
      "step": 237
    },
    {
      "epoch": 34.0,
      "grad_norm": 0.6635597348213196,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 4.6797,
      "step": 238
    },
    {
      "epoch": 34.142857142857146,
      "grad_norm": 0.6082004308700562,
      "learning_rate": 3.1714285714285715e-05,
      "loss": 3.4766,
      "step": 239
    },
    {
      "epoch": 34.285714285714285,
      "grad_norm": 1.822434902191162,
      "learning_rate": 3.142857142857143e-05,
      "loss": 5.1016,
      "step": 240
    },
    {
      "epoch": 34.285714285714285,
      "eval_loss": 4.0390625,
      "eval_runtime": 0.9252,
      "eval_samples_per_second": 2.162,
      "eval_steps_per_second": 2.162,
      "step": 240
    },
    {
      "epoch": 34.42857142857143,
      "grad_norm": 0.6613215804100037,
      "learning_rate": 3.114285714285715e-05,
      "loss": 3.8672,
      "step": 241
    },
    {
      "epoch": 34.57142857142857,
      "grad_norm": 0.6685727834701538,
      "learning_rate": 3.0857142857142856e-05,
      "loss": 3.7109,
      "step": 242
    },
    {
      "epoch": 34.714285714285715,
      "grad_norm": 0.6577582955360413,
      "learning_rate": 3.057142857142857e-05,
      "loss": 4.0938,
      "step": 243
    },
    {
      "epoch": 34.857142857142854,
      "grad_norm": 0.6377073526382446,
      "learning_rate": 3.0285714285714288e-05,
      "loss": 4.8438,
      "step": 244
    },
    {
      "epoch": 35.0,
      "grad_norm": 0.8057018518447876,
      "learning_rate": 3e-05,
      "loss": 3.8828,
      "step": 245
    },
    {
      "epoch": 35.142857142857146,
      "grad_norm": 0.8884297609329224,
      "learning_rate": 2.9714285714285717e-05,
      "loss": 3.8828,
      "step": 246
    },
    {
      "epoch": 35.285714285714285,
      "grad_norm": 0.708232045173645,
      "learning_rate": 2.9428571428571426e-05,
      "loss": 4.7344,
      "step": 247
    },
    {
      "epoch": 35.42857142857143,
      "grad_norm": 0.5676153898239136,
      "learning_rate": 2.9142857142857146e-05,
      "loss": 4.0078,
      "step": 248
    },
    {
      "epoch": 35.57142857142857,
      "grad_norm": 0.6571194529533386,
      "learning_rate": 2.885714285714286e-05,
      "loss": 3.9062,
      "step": 249
    },
    {
      "epoch": 35.714285714285715,
      "grad_norm": 1.6801493167877197,
      "learning_rate": 2.857142857142857e-05,
      "loss": 5.1797,
      "step": 250
    },
    {
      "epoch": 35.857142857142854,
      "grad_norm": 0.8599550127983093,
      "learning_rate": 2.8285714285714287e-05,
      "loss": 3.5,
      "step": 251
    },
    {
      "epoch": 36.0,
      "grad_norm": 0.628064751625061,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 3.8125,
      "step": 252
    },
    {
      "epoch": 36.142857142857146,
      "grad_norm": 0.6447594165802002,
      "learning_rate": 2.7714285714285716e-05,
      "loss": 3.8516,
      "step": 253
    },
    {
      "epoch": 36.285714285714285,
      "grad_norm": 0.7694755792617798,
      "learning_rate": 2.742857142857143e-05,
      "loss": 4.0703,
      "step": 254
    },
    {
      "epoch": 36.42857142857143,
      "grad_norm": 0.9872577786445618,
      "learning_rate": 2.714285714285714e-05,
      "loss": 3.8984,
      "step": 255
    },
    {
      "epoch": 36.57142857142857,
      "grad_norm": 0.6082037687301636,
      "learning_rate": 2.6857142857142857e-05,
      "loss": 3.7188,
      "step": 256
    },
    {
      "epoch": 36.714285714285715,
      "grad_norm": 0.5445157289505005,
      "learning_rate": 2.6571428571428576e-05,
      "loss": 3.4453,
      "step": 257
    },
    {
      "epoch": 36.857142857142854,
      "grad_norm": 0.9656111598014832,
      "learning_rate": 2.6285714285714286e-05,
      "loss": 5.1719,
      "step": 258
    },
    {
      "epoch": 37.0,
      "grad_norm": 5.5332183837890625,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 4.75,
      "step": 259
    },
    {
      "epoch": 37.142857142857146,
      "grad_norm": 0.5419849753379822,
      "learning_rate": 2.5714285714285714e-05,
      "loss": 3.4141,
      "step": 260
    },
    {
      "epoch": 37.142857142857146,
      "eval_loss": 4.0234375,
      "eval_runtime": 0.9217,
      "eval_samples_per_second": 2.17,
      "eval_steps_per_second": 2.17,
      "step": 260
    },
    {
      "epoch": 37.285714285714285,
      "grad_norm": 0.6830962300300598,
      "learning_rate": 2.542857142857143e-05,
      "loss": 3.7656,
      "step": 261
    },
    {
      "epoch": 37.42857142857143,
      "grad_norm": 0.6489395499229431,
      "learning_rate": 2.5142857142857147e-05,
      "loss": 3.8281,
      "step": 262
    },
    {
      "epoch": 37.57142857142857,
      "grad_norm": 0.9469571709632874,
      "learning_rate": 2.485714285714286e-05,
      "loss": 4.0703,
      "step": 263
    },
    {
      "epoch": 37.714285714285715,
      "grad_norm": 0.7643588781356812,
      "learning_rate": 2.4571428571428572e-05,
      "loss": 4.75,
      "step": 264
    },
    {
      "epoch": 37.857142857142854,
      "grad_norm": 0.5582113265991211,
      "learning_rate": 2.4285714285714288e-05,
      "loss": 3.7969,
      "step": 265
    },
    {
      "epoch": 38.0,
      "grad_norm": 1.061693549156189,
      "learning_rate": 2.4e-05,
      "loss": 5.2578,
      "step": 266
    },
    {
      "epoch": 38.142857142857146,
      "grad_norm": 0.7586472034454346,
      "learning_rate": 2.3714285714285717e-05,
      "loss": 4.8438,
      "step": 267
    },
    {
      "epoch": 38.285714285714285,
      "grad_norm": 0.6294409036636353,
      "learning_rate": 2.342857142857143e-05,
      "loss": 3.5469,
      "step": 268
    },
    {
      "epoch": 38.42857142857143,
      "grad_norm": 0.5443631410598755,
      "learning_rate": 2.3142857142857145e-05,
      "loss": 3.7266,
      "step": 269
    },
    {
      "epoch": 38.57142857142857,
      "grad_norm": 0.549973726272583,
      "learning_rate": 2.2857142857142858e-05,
      "loss": 3.8438,
      "step": 270
    },
    {
      "epoch": 38.714285714285715,
      "grad_norm": 0.9105658531188965,
      "learning_rate": 2.257142857142857e-05,
      "loss": 3.8984,
      "step": 271
    },
    {
      "epoch": 38.857142857142854,
      "grad_norm": 0.5151596069335938,
      "learning_rate": 2.2285714285714287e-05,
      "loss": 3.9062,
      "step": 272
    },
    {
      "epoch": 39.0,
      "grad_norm": 0.9688775539398193,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 5.1328,
      "step": 273
    },
    {
      "epoch": 39.142857142857146,
      "grad_norm": 0.7470522522926331,
      "learning_rate": 2.1714285714285715e-05,
      "loss": 4.5156,
      "step": 274
    },
    {
      "epoch": 39.285714285714285,
      "grad_norm": 2.215970516204834,
      "learning_rate": 2.1428571428571428e-05,
      "loss": 4.8281,
      "step": 275
    },
    {
      "epoch": 39.42857142857143,
      "grad_norm": 0.9599016308784485,
      "learning_rate": 2.1142857142857144e-05,
      "loss": 3.7891,
      "step": 276
    },
    {
      "epoch": 39.57142857142857,
      "grad_norm": 0.5958346128463745,
      "learning_rate": 2.0857142857142857e-05,
      "loss": 3.9531,
      "step": 277
    },
    {
      "epoch": 39.714285714285715,
      "grad_norm": 0.6342324614524841,
      "learning_rate": 2.0571428571428573e-05,
      "loss": 4.0,
      "step": 278
    },
    {
      "epoch": 39.857142857142854,
      "grad_norm": 0.6127417683601379,
      "learning_rate": 2.0285714285714286e-05,
      "loss": 3.7188,
      "step": 279
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.6774402260780334,
      "learning_rate": 2e-05,
      "loss": 4.1562,
      "step": 280
    },
    {
      "epoch": 40.0,
      "eval_loss": 4.0234375,
      "eval_runtime": 0.9235,
      "eval_samples_per_second": 2.166,
      "eval_steps_per_second": 2.166,
      "step": 280
    },
    {
      "epoch": 40.142857142857146,
      "grad_norm": 1.7771732807159424,
      "learning_rate": 1.9714285714285714e-05,
      "loss": 4.7656,
      "step": 281
    },
    {
      "epoch": 40.285714285714285,
      "grad_norm": 1.0047850608825684,
      "learning_rate": 1.942857142857143e-05,
      "loss": 5.1719,
      "step": 282
    },
    {
      "epoch": 40.42857142857143,
      "grad_norm": 0.6424885392189026,
      "learning_rate": 1.9142857142857143e-05,
      "loss": 3.7422,
      "step": 283
    },
    {
      "epoch": 40.57142857142857,
      "grad_norm": 0.6233955025672913,
      "learning_rate": 1.885714285714286e-05,
      "loss": 4.0938,
      "step": 284
    },
    {
      "epoch": 40.714285714285715,
      "grad_norm": 0.57463538646698,
      "learning_rate": 1.8571428571428572e-05,
      "loss": 3.7031,
      "step": 285
    },
    {
      "epoch": 40.857142857142854,
      "grad_norm": 0.6778367757797241,
      "learning_rate": 1.8285714285714288e-05,
      "loss": 4.0625,
      "step": 286
    },
    {
      "epoch": 41.0,
      "grad_norm": 0.6020932793617249,
      "learning_rate": 1.8e-05,
      "loss": 3.4844,
      "step": 287
    },
    {
      "epoch": 41.142857142857146,
      "grad_norm": 0.737549364566803,
      "learning_rate": 1.7714285714285713e-05,
      "loss": 4.0312,
      "step": 288
    },
    {
      "epoch": 41.285714285714285,
      "grad_norm": 0.5296834111213684,
      "learning_rate": 1.742857142857143e-05,
      "loss": 3.7891,
      "step": 289
    },
    {
      "epoch": 41.42857142857143,
      "grad_norm": 3.2836670875549316,
      "learning_rate": 1.7142857142857145e-05,
      "loss": 5.2656,
      "step": 290
    },
    {
      "epoch": 41.57142857142857,
      "grad_norm": 0.7575623989105225,
      "learning_rate": 1.6857142857142858e-05,
      "loss": 3.7188,
      "step": 291
    },
    {
      "epoch": 41.714285714285715,
      "grad_norm": 0.720935583114624,
      "learning_rate": 1.657142857142857e-05,
      "loss": 4.5078,
      "step": 292
    },
    {
      "epoch": 41.857142857142854,
      "grad_norm": 0.8437955379486084,
      "learning_rate": 1.6285714285714287e-05,
      "loss": 4.0625,
      "step": 293
    },
    {
      "epoch": 42.0,
      "grad_norm": 0.5912070274353027,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 3.4531,
      "step": 294
    },
    {
      "epoch": 42.142857142857146,
      "grad_norm": 0.677925705909729,
      "learning_rate": 1.5714285714285715e-05,
      "loss": 3.8984,
      "step": 295
    },
    {
      "epoch": 42.285714285714285,
      "grad_norm": 0.6340540051460266,
      "learning_rate": 1.5428571428571428e-05,
      "loss": 4.0859,
      "step": 296
    },
    {
      "epoch": 42.42857142857143,
      "grad_norm": 1.3936288356781006,
      "learning_rate": 1.5142857142857144e-05,
      "loss": 4.6328,
      "step": 297
    },
    {
      "epoch": 42.57142857142857,
      "grad_norm": 0.6202881932258606,
      "learning_rate": 1.4857142857142858e-05,
      "loss": 3.5469,
      "step": 298
    },
    {
      "epoch": 42.714285714285715,
      "grad_norm": 1.131738305091858,
      "learning_rate": 1.4571428571428573e-05,
      "loss": 5.0703,
      "step": 299
    },
    {
      "epoch": 42.857142857142854,
      "grad_norm": 0.9981753826141357,
      "learning_rate": 1.4285714285714285e-05,
      "loss": 3.6484,
      "step": 300
    },
    {
      "epoch": 42.857142857142854,
      "eval_loss": 4.0234375,
      "eval_runtime": 0.9255,
      "eval_samples_per_second": 2.161,
      "eval_steps_per_second": 2.161,
      "step": 300
    },
    {
      "epoch": 43.0,
      "grad_norm": 0.6506751179695129,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 3.9688,
      "step": 301
    },
    {
      "epoch": 43.142857142857146,
      "grad_norm": 1.0164152383804321,
      "learning_rate": 1.3714285714285716e-05,
      "loss": 4.0547,
      "step": 302
    },
    {
      "epoch": 43.285714285714285,
      "grad_norm": 0.55983966588974,
      "learning_rate": 1.3428571428571429e-05,
      "loss": 3.4453,
      "step": 303
    },
    {
      "epoch": 43.42857142857143,
      "grad_norm": 0.6415424346923828,
      "learning_rate": 1.3142857142857143e-05,
      "loss": 3.8047,
      "step": 304
    },
    {
      "epoch": 43.57142857142857,
      "grad_norm": 0.952121376991272,
      "learning_rate": 1.2857142857142857e-05,
      "loss": 5.1172,
      "step": 305
    },
    {
      "epoch": 43.714285714285715,
      "grad_norm": 0.6751527190208435,
      "learning_rate": 1.2571428571428573e-05,
      "loss": 3.9531,
      "step": 306
    },
    {
      "epoch": 43.857142857142854,
      "grad_norm": 0.6431119441986084,
      "learning_rate": 1.2285714285714286e-05,
      "loss": 4.7344,
      "step": 307
    },
    {
      "epoch": 44.0,
      "grad_norm": 0.6278129816055298,
      "learning_rate": 1.2e-05,
      "loss": 3.6953,
      "step": 308
    },
    {
      "epoch": 44.142857142857146,
      "grad_norm": 0.6485762000083923,
      "learning_rate": 1.1714285714285715e-05,
      "loss": 3.7266,
      "step": 309
    },
    {
      "epoch": 44.285714285714285,
      "grad_norm": 1.039979100227356,
      "learning_rate": 1.1428571428571429e-05,
      "loss": 5.0859,
      "step": 310
    },
    {
      "epoch": 44.42857142857143,
      "grad_norm": 0.6752543449401855,
      "learning_rate": 1.1142857142857143e-05,
      "loss": 4.8125,
      "step": 311
    },
    {
      "epoch": 44.57142857142857,
      "grad_norm": 0.6734715104103088,
      "learning_rate": 1.0857142857142858e-05,
      "loss": 3.8359,
      "step": 312
    },
    {
      "epoch": 44.714285714285715,
      "grad_norm": 0.8283038139343262,
      "learning_rate": 1.0571428571428572e-05,
      "loss": 3.7969,
      "step": 313
    },
    {
      "epoch": 44.857142857142854,
      "grad_norm": 1.0254484415054321,
      "learning_rate": 1.0285714285714286e-05,
      "loss": 3.7344,
      "step": 314
    },
    {
      "epoch": 45.0,
      "grad_norm": 0.6800813674926758,
      "learning_rate": 1e-05,
      "loss": 3.7734,
      "step": 315
    },
    {
      "epoch": 45.142857142857146,
      "grad_norm": 0.6653444170951843,
      "learning_rate": 9.714285714285715e-06,
      "loss": 3.9531,
      "step": 316
    },
    {
      "epoch": 45.285714285714285,
      "grad_norm": 0.9838947653770447,
      "learning_rate": 9.42857142857143e-06,
      "loss": 3.4375,
      "step": 317
    },
    {
      "epoch": 45.42857142857143,
      "grad_norm": 1.1514203548431396,
      "learning_rate": 9.142857142857144e-06,
      "loss": 4.5078,
      "step": 318
    },
    {
      "epoch": 45.57142857142857,
      "grad_norm": 0.673775315284729,
      "learning_rate": 8.857142857142857e-06,
      "loss": 3.9375,
      "step": 319
    },
    {
      "epoch": 45.714285714285715,
      "grad_norm": 0.5796980261802673,
      "learning_rate": 8.571428571428573e-06,
      "loss": 3.7109,
      "step": 320
    },
    {
      "epoch": 45.714285714285715,
      "eval_loss": 4.0234375,
      "eval_runtime": 0.9242,
      "eval_samples_per_second": 2.164,
      "eval_steps_per_second": 2.164,
      "step": 320
    },
    {
      "epoch": 45.857142857142854,
      "grad_norm": 1.1926662921905518,
      "learning_rate": 8.285714285714285e-06,
      "loss": 5.1406,
      "step": 321
    },
    {
      "epoch": 46.0,
      "grad_norm": 0.7118937969207764,
      "learning_rate": 8.000000000000001e-06,
      "loss": 4.1641,
      "step": 322
    },
    {
      "epoch": 46.142857142857146,
      "grad_norm": 0.6751416921615601,
      "learning_rate": 7.714285714285714e-06,
      "loss": 4.0547,
      "step": 323
    },
    {
      "epoch": 46.285714285714285,
      "grad_norm": 0.6427380442619324,
      "learning_rate": 7.428571428571429e-06,
      "loss": 4.6172,
      "step": 324
    },
    {
      "epoch": 46.42857142857143,
      "grad_norm": 0.6103253364562988,
      "learning_rate": 7.142857142857143e-06,
      "loss": 3.8984,
      "step": 325
    },
    {
      "epoch": 46.57142857142857,
      "grad_norm": 0.6371912956237793,
      "learning_rate": 6.857142857142858e-06,
      "loss": 3.3125,
      "step": 326
    },
    {
      "epoch": 46.714285714285715,
      "grad_norm": 0.5670386552810669,
      "learning_rate": 6.5714285714285714e-06,
      "loss": 3.6953,
      "step": 327
    },
    {
      "epoch": 46.857142857142854,
      "grad_norm": 1.0240249633789062,
      "learning_rate": 6.285714285714287e-06,
      "loss": 5.1328,
      "step": 328
    },
    {
      "epoch": 47.0,
      "grad_norm": 1.022432565689087,
      "learning_rate": 6e-06,
      "loss": 4.0703,
      "step": 329
    },
    {
      "epoch": 47.142857142857146,
      "grad_norm": 0.9041407704353333,
      "learning_rate": 5.7142857142857145e-06,
      "loss": 3.9531,
      "step": 330
    },
    {
      "epoch": 47.285714285714285,
      "grad_norm": 0.560644805431366,
      "learning_rate": 5.428571428571429e-06,
      "loss": 3.4844,
      "step": 331
    },
    {
      "epoch": 47.42857142857143,
      "grad_norm": 0.648870587348938,
      "learning_rate": 5.142857142857143e-06,
      "loss": 3.7891,
      "step": 332
    },
    {
      "epoch": 47.57142857142857,
      "grad_norm": 1.9399453401565552,
      "learning_rate": 4.857142857142858e-06,
      "loss": 4.7266,
      "step": 333
    },
    {
      "epoch": 47.714285714285715,
      "grad_norm": 0.6434312462806702,
      "learning_rate": 4.571428571428572e-06,
      "loss": 3.5625,
      "step": 334
    },
    {
      "epoch": 47.857142857142854,
      "grad_norm": 0.9251134395599365,
      "learning_rate": 4.285714285714286e-06,
      "loss": 5.0859,
      "step": 335
    },
    {
      "epoch": 48.0,
      "grad_norm": 0.6748743057250977,
      "learning_rate": 4.000000000000001e-06,
      "loss": 4.125,
      "step": 336
    },
    {
      "epoch": 48.142857142857146,
      "grad_norm": 0.876635730266571,
      "learning_rate": 3.7142857142857146e-06,
      "loss": 3.9922,
      "step": 337
    },
    {
      "epoch": 48.285714285714285,
      "grad_norm": 0.8216397762298584,
      "learning_rate": 3.428571428571429e-06,
      "loss": 5.0078,
      "step": 338
    },
    {
      "epoch": 48.42857142857143,
      "grad_norm": 0.5675581693649292,
      "learning_rate": 3.1428571428571433e-06,
      "loss": 3.4375,
      "step": 339
    },
    {
      "epoch": 48.57142857142857,
      "grad_norm": 0.7056859135627747,
      "learning_rate": 2.8571428571428573e-06,
      "loss": 4.1562,
      "step": 340
    },
    {
      "epoch": 48.57142857142857,
      "eval_loss": 4.0234375,
      "eval_runtime": 0.9291,
      "eval_samples_per_second": 2.153,
      "eval_steps_per_second": 2.153,
      "step": 340
    },
    {
      "epoch": 48.714285714285715,
      "grad_norm": 0.5949735641479492,
      "learning_rate": 2.5714285714285716e-06,
      "loss": 4.5234,
      "step": 341
    },
    {
      "epoch": 48.857142857142854,
      "grad_norm": 1.1184781789779663,
      "learning_rate": 2.285714285714286e-06,
      "loss": 3.9141,
      "step": 342
    },
    {
      "epoch": 49.0,
      "grad_norm": 0.5798258185386658,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 3.8672,
      "step": 343
    },
    {
      "epoch": 49.142857142857146,
      "grad_norm": 0.6806685924530029,
      "learning_rate": 1.7142857142857145e-06,
      "loss": 4.1875,
      "step": 344
    },
    {
      "epoch": 49.285714285714285,
      "grad_norm": 0.603437602519989,
      "learning_rate": 1.4285714285714286e-06,
      "loss": 3.7422,
      "step": 345
    },
    {
      "epoch": 49.42857142857143,
      "grad_norm": 0.9688519239425659,
      "learning_rate": 1.142857142857143e-06,
      "loss": 4.6562,
      "step": 346
    },
    {
      "epoch": 49.57142857142857,
      "grad_norm": 0.8480704426765442,
      "learning_rate": 8.571428571428572e-07,
      "loss": 3.8359,
      "step": 347
    },
    {
      "epoch": 49.714285714285715,
      "grad_norm": 1.6091176271438599,
      "learning_rate": 5.714285714285715e-07,
      "loss": 5.0938,
      "step": 348
    },
    {
      "epoch": 49.857142857142854,
      "grad_norm": 0.6217589378356934,
      "learning_rate": 2.8571428571428575e-07,
      "loss": 3.3125,
      "step": 349
    },
    {
      "epoch": 50.0,
      "grad_norm": 1.0063107013702393,
      "learning_rate": 0.0,
      "loss": 3.9297,
      "step": 350
    }
  ],
  "logging_steps": 1,
  "max_steps": 350,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7601160978432000.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
